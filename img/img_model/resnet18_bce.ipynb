{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import shutil\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path=\"/home/chohj/test_image/normal\"\n",
    "file_list=os.listdir(path)\n",
    "test_n=[file for file in file_list if file.endswith(\".jpg\")] \n",
    "\n",
    "path=\"/home/chohj//test_image/unnormal\"\n",
    "file_list=os.listdir(path)\n",
    "test_un=[file for file in file_list if file.endswith(\".jpg\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/chohj/train_image/normal\"\n",
    "file_list=os.listdir(path)\n",
    "train_n=[file for file in file_list if file.endswith(\".jpg\")] \n",
    "\n",
    "path=\"/home/chohj/train_image/unnormal\"\n",
    "file_list=os.listdir(path)\n",
    "train_un=[file for file in file_list if file.endswith(\".jpg\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/chohj/val_image/normal\"\n",
    "file_list=os.listdir(path)\n",
    "valid_n=[file for file in file_list if file.endswith(\".jpg\")] \n",
    "\n",
    "path=\"/home/chohj/val_image/unnormal\"\n",
    "file_list=os.listdir(path)\n",
    "valid_un=[file for file in file_list if file.endswith(\".jpg\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset1(torch.utils.data.Dataset):\n",
    "    def __init__(self, files, root, mode='train', transform=None):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.transform=transform\n",
    "        self.label = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = PIL.Image.open(os.path.join(self.root, self.files[index]))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            return img, np.array([self.label])\n",
    "        else:\n",
    "            return img, self.files[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, files, root, mode='train', transform=None):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.transform=transform\n",
    "        self.label = 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = PIL.Image.open(os.path.join(self.root, self.files[index]))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            return img, np.array([self.label])\n",
    "        else:\n",
    "            return img, self.files[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "torchvision.transforms.Resize((440,224)),\n",
    "torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "torchvision.transforms.Resize((440,224)),\n",
    "torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/chohj/train.csv')\n",
    "df2 = pd.read_csv('/home/chohj/valid.csv')\n",
    "df3 = pd.read_csv('/home/chohj/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_dataset = CustomDataset1(train_n, '/home/chohj/train_image/normal', transform=train_transform)\n",
    "train_unnormal_dataset = CustomDataset2(train_un, '/home/chohj/train_image/unnormal', transform=train_transform)\n",
    "valid_normal_dataset = CustomDataset1(valid_n, '/home/chohj/val_image/normal', transform=test_transform)\n",
    "valid_unnormal_dataset = CustomDataset2(valid_un, '/home/chohj/val_image/unnormal', transform=test_transform)\n",
    "test_normal_dataset = CustomDataset1(test_n, '/home/chohj/test_image/normal', transform=test_transform)\n",
    "test_unnormal_dataset = CustomDataset2(test_un, '/home/chohj/test_image/unnormal', transform=test_transform)\n",
    " \n",
    "train_dataset = torch.utils.data.ConcatDataset([train_normal_dataset, train_unnormal_dataset])\n",
    "valid_dataset = torch.utils.data.ConcatDataset([valid_normal_dataset, valid_unnormal_dataset])\n",
    "test_dataset = torch.utils.data.ConcatDataset([test_normal_dataset, test_unnormal_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_nor = os.listdir('/home/chohj/train_image/normal')\n",
    "tr_unnor = os.listdir('/home/chohj/train_image/unnormal')\n",
    "\n",
    "print('nor : {0} /  unnom:{1}'.format(len(tr_nor),len(tr_unnor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of train dataset : {len(train_dataset)}')\n",
    "print(f'number of valid dataset : {len(valid_dataset)}')\n",
    "print(f'number of test dataset : {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 확인\n",
    "samples, labels = iter(train_loader).next()\n",
    "classes = {0:'normal', 1:'unnormal'}\n",
    "fig = plt.figure(figsize=(16,24))\n",
    "for i in range(24):\n",
    "    a = fig.add_subplot(4,6,i+1)\n",
    "    a.set_title(classes[labels[i].item()])\n",
    "    a.axis('off')\n",
    "    a.imshow(np.transpose(samples[i].numpy(), (1,2,0)))\n",
    "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "nn.Dropout(0.5),\n",
    "nn.Linear(num_ftrs, 256),\n",
    "nn.Tanh(),\n",
    "nn.Dropout(),\n",
    "nn.Linear(256, 1),\n",
    "nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Sequential(\n",
    "# nn.Dropout(0.5),\n",
    "# nn.Linear(num_ftrs, 1024),\n",
    "# nn.Dropout(0.2),\n",
    "# nn.Linear(1024, 512),\n",
    "# nn.Dropout(0.1),\n",
    "# nn.Linear(512, 1),\n",
    "# nn.Sigmoid()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 220, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 220, 112]             128\n",
      "              ReLU-3         [-1, 64, 220, 112]               0\n",
      "         MaxPool2d-4          [-1, 64, 110, 56]               0\n",
      "            Conv2d-5          [-1, 64, 110, 56]          36,864\n",
      "       BatchNorm2d-6          [-1, 64, 110, 56]             128\n",
      "              ReLU-7          [-1, 64, 110, 56]               0\n",
      "            Conv2d-8          [-1, 64, 110, 56]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 110, 56]             128\n",
      "             ReLU-10          [-1, 64, 110, 56]               0\n",
      "       BasicBlock-11          [-1, 64, 110, 56]               0\n",
      "           Conv2d-12          [-1, 64, 110, 56]          36,864\n",
      "      BatchNorm2d-13          [-1, 64, 110, 56]             128\n",
      "             ReLU-14          [-1, 64, 110, 56]               0\n",
      "           Conv2d-15          [-1, 64, 110, 56]          36,864\n",
      "      BatchNorm2d-16          [-1, 64, 110, 56]             128\n",
      "             ReLU-17          [-1, 64, 110, 56]               0\n",
      "       BasicBlock-18          [-1, 64, 110, 56]               0\n",
      "           Conv2d-19          [-1, 128, 55, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 55, 28]             256\n",
      "             ReLU-21          [-1, 128, 55, 28]               0\n",
      "           Conv2d-22          [-1, 128, 55, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 55, 28]             256\n",
      "           Conv2d-24          [-1, 128, 55, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 55, 28]             256\n",
      "             ReLU-26          [-1, 128, 55, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 55, 28]               0\n",
      "           Conv2d-28          [-1, 128, 55, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 55, 28]             256\n",
      "             ReLU-30          [-1, 128, 55, 28]               0\n",
      "           Conv2d-31          [-1, 128, 55, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 55, 28]             256\n",
      "             ReLU-33          [-1, 128, 55, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 55, 28]               0\n",
      "           Conv2d-35          [-1, 256, 28, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 28, 14]             512\n",
      "             ReLU-37          [-1, 256, 28, 14]               0\n",
      "           Conv2d-38          [-1, 256, 28, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 28, 14]             512\n",
      "           Conv2d-40          [-1, 256, 28, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 28, 14]             512\n",
      "             ReLU-42          [-1, 256, 28, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 28, 14]               0\n",
      "           Conv2d-44          [-1, 256, 28, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 28, 14]             512\n",
      "             ReLU-46          [-1, 256, 28, 14]               0\n",
      "           Conv2d-47          [-1, 256, 28, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 28, 14]             512\n",
      "             ReLU-49          [-1, 256, 28, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 28, 14]               0\n",
      "           Conv2d-51           [-1, 512, 14, 7]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 14, 7]           1,024\n",
      "             ReLU-53           [-1, 512, 14, 7]               0\n",
      "           Conv2d-54           [-1, 512, 14, 7]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 14, 7]           1,024\n",
      "           Conv2d-56           [-1, 512, 14, 7]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 14, 7]           1,024\n",
      "             ReLU-58           [-1, 512, 14, 7]               0\n",
      "       BasicBlock-59           [-1, 512, 14, 7]               0\n",
      "           Conv2d-60           [-1, 512, 14, 7]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 14, 7]           1,024\n",
      "             ReLU-62           [-1, 512, 14, 7]               0\n",
      "           Conv2d-63           [-1, 512, 14, 7]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 14, 7]           1,024\n",
      "             ReLU-65           [-1, 512, 14, 7]               0\n",
      "       BasicBlock-66           [-1, 512, 14, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "          Dropout-68                  [-1, 512]               0\n",
      "           Linear-69                  [-1, 256]         131,328\n",
      "             Tanh-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                    [-1, 1]             257\n",
      "          Sigmoid-73                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,308,097\n",
      "Trainable params: 11,308,097\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.13\n",
      "Forward/backward pass size (MB): 123.66\n",
      "Params size (MB): 43.14\n",
      "Estimated Total Size (MB): 167.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = model.to(device)\n",
    "summary(model, input_size=(3,440,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimizer, epochs, train_loader, valid_loader):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for train_x, train_y in train_loader:\n",
    "            model.train()\n",
    "            train_x, train_y = train_x.to(device), train_y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(train_x)\n",
    "            loss = criterion(pred, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            y_pred = pred.cpu()\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "            train_correct += y_pred.eq(train_y.cpu()).int().sum()\n",
    "        # validation data check\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_correct = 0\n",
    "        for valid_x, valid_y in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_x, valid_y = valid_x.to(device), valid_y.to(device).float()\n",
    "                pred = model(valid_x)\n",
    "                loss = criterion(pred, valid_y)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            y_pred = pred.cpu()\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "            valid_correct += y_pred.eq(valid_y.cpu()).int().sum()\n",
    "\n",
    "        train_acc = train_correct/len(train_loader.dataset)\n",
    "        valid_acc = valid_correct/len(valid_loader.dataset)\n",
    "\n",
    "        print(f'{time.time() - start:.3f}sec : [Epoch {epoch+1}/{epochs}] -> train loss: {train_loss/ len(train_loader):.4f}, train acc: {train_acc*100:.3f}% / valid loss: {valid_loss/len(valid_loader):.4f}, valid acc: {valid_acc*100:.3f}%')\n",
    "    \n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss/len(valid_loader))\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_correct = 0\n",
    "\n",
    "    plt.plot(train_losses, label='loss')\n",
    "    plt.plot(train_accuracies, label='accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('train loss and accuracy')\n",
    "    plt.show()\n",
    "    plt.plot(valid_losses, label='loss')\n",
    "    plt.plot(valid_accuracies, label='accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('valid loss and accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.710sec : [Epoch 1/100] -> train loss: 0.6929, train acc: 59.996% / valid loss: 0.7684, valid acc: 55.244%\n",
      "18.532sec : [Epoch 2/100] -> train loss: 0.6588, train acc: 62.553% / valid loss: 0.6449, valid acc: 63.109%\n",
      "18.457sec : [Epoch 3/100] -> train loss: 0.6592, train acc: 61.495% / valid loss: 0.6817, valid acc: 59.660%\n",
      "18.740sec : [Epoch 4/100] -> train loss: 0.6576, train acc: 63.011% / valid loss: 0.6690, valid acc: 57.544%\n",
      "18.683sec : [Epoch 5/100] -> train loss: 0.6562, train acc: 63.293% / valid loss: 0.6973, valid acc: 61.730%\n",
      "18.324sec : [Epoch 6/100] -> train loss: 0.6556, train acc: 63.434% / valid loss: 0.7667, valid acc: 61.822%\n",
      "18.464sec : [Epoch 7/100] -> train loss: 0.6640, train acc: 60.807% / valid loss: 0.6559, valid acc: 54.370%\n",
      "19.531sec : [Epoch 8/100] -> train loss: 0.6503, train acc: 62.712% / valid loss: 0.6763, valid acc: 61.224%\n",
      "19.149sec : [Epoch 9/100] -> train loss: 0.6622, train acc: 62.412% / valid loss: 0.6270, valid acc: 63.017%\n",
      "19.177sec : [Epoch 10/100] -> train loss: 0.6622, train acc: 61.901% / valid loss: 0.6287, valid acc: 60.764%\n",
      "19.430sec : [Epoch 11/100] -> train loss: 0.6536, train acc: 62.782% / valid loss: 0.6316, valid acc: 58.924%\n",
      "19.414sec : [Epoch 12/100] -> train loss: 0.6641, train acc: 61.883% / valid loss: 0.7106, valid acc: 55.014%\n",
      "19.546sec : [Epoch 13/100] -> train loss: 0.6568, train acc: 62.835% / valid loss: 0.6605, valid acc: 61.270%\n",
      "19.189sec : [Epoch 14/100] -> train loss: 0.6743, train acc: 61.760% / valid loss: 0.6207, valid acc: 61.178%\n",
      "18.627sec : [Epoch 15/100] -> train loss: 0.6447, train acc: 63.029% / valid loss: 0.6527, valid acc: 60.810%\n",
      "18.792sec : [Epoch 16/100] -> train loss: 0.6597, train acc: 62.377% / valid loss: 0.7959, valid acc: 59.522%\n",
      "18.516sec : [Epoch 17/100] -> train loss: 0.6498, train acc: 63.575% / valid loss: 0.6333, valid acc: 61.132%\n",
      "18.414sec : [Epoch 18/100] -> train loss: 0.6441, train acc: 63.135% / valid loss: 0.6448, valid acc: 63.615%\n",
      "18.601sec : [Epoch 19/100] -> train loss: 0.6477, train acc: 64.210% / valid loss: 0.6783, valid acc: 62.557%\n",
      "18.589sec : [Epoch 20/100] -> train loss: 0.6504, train acc: 63.716% / valid loss: 0.6805, valid acc: 62.190%\n",
      "18.539sec : [Epoch 21/100] -> train loss: 0.6518, train acc: 63.258% / valid loss: 0.6304, valid acc: 62.787%\n",
      "18.472sec : [Epoch 22/100] -> train loss: 0.6401, train acc: 64.069% / valid loss: 0.6518, valid acc: 61.362%\n",
      "18.326sec : [Epoch 23/100] -> train loss: 0.6488, train acc: 64.757% / valid loss: 0.6371, valid acc: 62.374%\n",
      "18.615sec : [Epoch 24/100] -> train loss: 0.6366, train acc: 64.457% / valid loss: 0.6229, valid acc: 61.270%\n",
      "18.533sec : [Epoch 25/100] -> train loss: 0.6385, train acc: 63.311% / valid loss: 0.6466, valid acc: 65.639%\n",
      "18.916sec : [Epoch 26/100] -> train loss: 0.6496, train acc: 64.051% / valid loss: 0.6577, valid acc: 64.029%\n",
      "19.463sec : [Epoch 27/100] -> train loss: 0.6449, train acc: 63.769% / valid loss: 0.6410, valid acc: 60.488%\n",
      "19.608sec : [Epoch 28/100] -> train loss: 0.6355, train acc: 64.140% / valid loss: 0.6447, valid acc: 61.224%\n",
      "19.868sec : [Epoch 29/100] -> train loss: 0.6417, train acc: 64.810% / valid loss: 0.6481, valid acc: 62.787%\n",
      "19.828sec : [Epoch 30/100] -> train loss: 0.6514, train acc: 63.470% / valid loss: 0.6356, valid acc: 61.086%\n",
      "19.524sec : [Epoch 31/100] -> train loss: 0.6434, train acc: 63.910% / valid loss: 0.6705, valid acc: 61.362%\n",
      "19.650sec : [Epoch 32/100] -> train loss: 0.6455, train acc: 64.281% / valid loss: 0.6172, valid acc: 64.489%\n",
      "19.866sec : [Epoch 33/100] -> train loss: 0.6394, train acc: 64.827% / valid loss: 0.7666, valid acc: 54.370%\n",
      "19.140sec : [Epoch 34/100] -> train loss: 0.6441, train acc: 64.404% / valid loss: 0.6177, valid acc: 64.029%\n",
      "18.544sec : [Epoch 35/100] -> train loss: 0.6376, train acc: 63.963% / valid loss: 0.6808, valid acc: 64.305%\n",
      "18.565sec : [Epoch 36/100] -> train loss: 0.6552, train acc: 63.276% / valid loss: 0.6390, valid acc: 66.191%\n",
      "18.663sec : [Epoch 37/100] -> train loss: 0.6352, train acc: 64.580% / valid loss: 0.6461, valid acc: 63.661%\n",
      "18.457sec : [Epoch 38/100] -> train loss: 0.6383, train acc: 64.810% / valid loss: 0.6570, valid acc: 61.270%\n",
      "18.481sec : [Epoch 39/100] -> train loss: 0.6378, train acc: 64.774% / valid loss: 0.6970, valid acc: 57.084%\n",
      "18.438sec : [Epoch 40/100] -> train loss: 0.6415, train acc: 64.580% / valid loss: 0.6758, valid acc: 61.132%\n",
      "18.707sec : [Epoch 41/100] -> train loss: 0.6279, train acc: 65.004% / valid loss: 0.6387, valid acc: 56.578%\n",
      "18.241sec : [Epoch 42/100] -> train loss: 0.6291, train acc: 65.815% / valid loss: 0.6046, valid acc: 67.847%\n",
      "18.456sec : [Epoch 43/100] -> train loss: 0.6340, train acc: 65.303% / valid loss: 0.5856, valid acc: 68.859%\n",
      "18.242sec : [Epoch 44/100] -> train loss: 0.6235, train acc: 66.008% / valid loss: 0.5989, valid acc: 65.041%\n",
      "18.493sec : [Epoch 45/100] -> train loss: 0.6497, train acc: 63.646% / valid loss: 0.6386, valid acc: 61.868%\n",
      "18.422sec : [Epoch 46/100] -> train loss: 0.6223, train acc: 65.656% / valid loss: 0.6141, valid acc: 64.995%\n",
      "18.384sec : [Epoch 47/100] -> train loss: 0.6238, train acc: 67.154% / valid loss: 0.6290, valid acc: 65.317%\n",
      "18.463sec : [Epoch 48/100] -> train loss: 0.6253, train acc: 66.978% / valid loss: 0.6439, valid acc: 63.339%\n",
      "18.375sec : [Epoch 49/100] -> train loss: 0.6093, train acc: 67.049% / valid loss: 0.6325, valid acc: 62.282%\n",
      "18.506sec : [Epoch 50/100] -> train loss: 0.6304, train acc: 65.444% / valid loss: 0.5973, valid acc: 65.363%\n",
      "18.457sec : [Epoch 51/100] -> train loss: 0.6256, train acc: 65.286% / valid loss: 0.6214, valid acc: 66.467%\n",
      "18.424sec : [Epoch 52/100] -> train loss: 0.6041, train acc: 67.172% / valid loss: 0.6229, valid acc: 65.593%\n",
      "18.359sec : [Epoch 53/100] -> train loss: 0.6142, train acc: 66.661% / valid loss: 0.6955, valid acc: 64.029%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "fit(model, criterion, optimizer, 100, train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, criterion, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        losses = 0\n",
    "        t1 = time.time()\n",
    "        for test_x, test_y in test_loader:\n",
    "            test_x, test_y = test_x.to(device), test_y.to(device).float()\n",
    "            pred = model(test_x)\n",
    "            loss = criterion(pred, test_y)\n",
    "            \n",
    "            y_pred = pred.cpu()\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "            losses += loss.item()\n",
    "            correct += y_pred.eq(test_y.cpu()).int().sum()\n",
    "            t2 = time.time()\n",
    "            infer_time = (t2 - t1) * 1000\n",
    "            print(f'eval loss: {losses/len(test_loader):.4f}, eval acc: {correct/len(test_loader.dataset)*100:.3f}%')\n",
    "            print(infer_time)\n",
    "        print('all time : ', (time.time - t1)*1000 / 1941)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.0070, eval acc: 1.340%\n",
      "eval loss: 0.0155, eval acc: 2.421%\n",
      "eval loss: 0.0250, eval acc: 3.606%\n",
      "eval loss: 0.0302, eval acc: 5.049%\n",
      "eval loss: 0.0382, eval acc: 6.285%\n",
      "eval loss: 0.0455, eval acc: 7.419%\n",
      "eval loss: 0.0511, eval acc: 8.913%\n",
      "eval loss: 0.0577, eval acc: 10.252%\n",
      "eval loss: 0.0657, eval acc: 11.540%\n",
      "eval loss: 0.0724, eval acc: 12.880%\n",
      "eval loss: 0.0830, eval acc: 13.910%\n",
      "eval loss: 0.0916, eval acc: 15.095%\n",
      "eval loss: 0.0979, eval acc: 16.538%\n",
      "eval loss: 0.1047, eval acc: 17.877%\n",
      "eval loss: 0.1132, eval acc: 19.011%\n",
      "eval loss: 0.1185, eval acc: 20.453%\n",
      "eval loss: 0.1263, eval acc: 21.587%\n",
      "eval loss: 0.1345, eval acc: 22.772%\n",
      "eval loss: 0.1433, eval acc: 23.957%\n",
      "eval loss: 0.1495, eval acc: 25.348%\n",
      "eval loss: 0.1563, eval acc: 26.636%\n",
      "eval loss: 0.1631, eval acc: 27.975%\n",
      "eval loss: 0.1711, eval acc: 29.263%\n",
      "eval loss: 0.1787, eval acc: 30.551%\n",
      "eval loss: 0.1863, eval acc: 31.736%\n",
      "eval loss: 0.1932, eval acc: 33.127%\n",
      "eval loss: 0.2018, eval acc: 34.312%\n",
      "eval loss: 0.2074, eval acc: 35.703%\n",
      "eval loss: 0.2141, eval acc: 36.991%\n",
      "eval loss: 0.2210, eval acc: 38.382%\n",
      "eval loss: 0.2288, eval acc: 39.722%\n",
      "eval loss: 0.2365, eval acc: 41.061%\n",
      "eval loss: 0.2418, eval acc: 42.555%\n",
      "eval loss: 0.2493, eval acc: 43.792%\n",
      "eval loss: 0.2563, eval acc: 45.131%\n",
      "eval loss: 0.2651, eval acc: 46.368%\n",
      "eval loss: 0.2713, eval acc: 47.759%\n",
      "eval loss: 0.2794, eval acc: 49.047%\n",
      "eval loss: 0.2883, eval acc: 50.180%\n",
      "eval loss: 0.2952, eval acc: 51.520%\n",
      "eval loss: 0.3012, eval acc: 52.808%\n",
      "eval loss: 0.3078, eval acc: 54.147%\n",
      "eval loss: 0.3177, eval acc: 55.178%\n",
      "eval loss: 0.3238, eval acc: 56.620%\n",
      "eval loss: 0.3317, eval acc: 57.908%\n",
      "eval loss: 0.3406, eval acc: 58.990%\n",
      "eval loss: 0.3482, eval acc: 60.330%\n",
      "eval loss: 0.3553, eval acc: 61.618%\n",
      "eval loss: 0.3617, eval acc: 62.957%\n",
      "eval loss: 0.3691, eval acc: 64.297%\n",
      "eval loss: 0.3740, eval acc: 65.688%\n",
      "eval loss: 0.3805, eval acc: 67.027%\n",
      "eval loss: 0.3852, eval acc: 68.521%\n",
      "eval loss: 0.3940, eval acc: 69.603%\n",
      "eval loss: 0.4008, eval acc: 70.943%\n",
      "eval loss: 0.4107, eval acc: 72.025%\n",
      "eval loss: 0.4188, eval acc: 73.210%\n",
      "eval loss: 0.4243, eval acc: 74.704%\n",
      "eval loss: 0.4350, eval acc: 75.631%\n",
      "eval loss: 0.4413, eval acc: 76.971%\n",
      "eval loss: 0.4512, eval acc: 77.743%\n"
     ]
    }
   ],
   "source": [
    "eval(model, criterion, test_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fa1c3bda4c278fb76e2aeca93ebb14596ce5096c5a0bdf3b6c07c256293942c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
